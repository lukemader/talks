\subsection{Definition of an unbounded operator}

We start by giving the definition of an unbounded operator.

\begin{definition}[{\cite[Definition 3.1]{Hall2013}}]
  For a Hilbert space $\HS$, an {\emph{(unbounded) operator in
  $\HS$}} is a linear map $T$ whose domain, $\dom{T}$, is a subspace of $\HS$, and whose range, $\range{T}$, is contained in $\HS$. We say that $T$ is {\emph{densely-defined}} if $\dom{T}$ is dense in $\HS$.
\end{definition}
We note that some authors, such as {\cite{Hall2013}} and {\cite{konrad}}, prefer to use the phrase `an operator {\emph{on}} (a Hilbert space) $\HS$'. We will use the phrase `an operator {\emph{in}} (a Hilbert space) $\HS$', which is used in {\cite{teschl}}, {\cite{analysis_now}}, and {\cite{kreyszig}}, as we find it more descriptive. We also note that the definition here of an unbounded operator is a not necessarily bounded operator, rather than a not bounded operator. As we still require our operators to be linear, it is worth noting that we still have the kernel and range of our operators being subspaces of the underlying Hilbert space. This can be easily verified through the subspace test.

\medskip

Throughout the rest of our work, {\emph{we will assume that our operators are unbounded and densely-defined, unless stated otherwise}}. We will sometimes state that an operator is densely-defined to emphasise the importance of the characteristic in what we are doing. It follows from the definition that densely-defined operators can only live in a separable Hilbert space. We therefore assume from here on that the Hilbert space is separable when we work with densely-defined functions.

\medskip

Over time, it will become clear why we want to define our unbounded operators on dense subspaces of $\HS$. The following example is quite useful in motivating this, and we will see it a few times through our journey. Recall that $L^2(\R)$ is the space of square-integrable functions (which are representatives of equivalence classes) with respect to the Lebesgue measure. This is a Hilbert space with the standard norm for the space, and is formally defined in Definition {\eqref{lbl_def_L2}} and Proposition \eqref{lbl_L2_hilbert}.
\begin{example}[{\cite[Lemma 10.7-1]{kreyszig}}]\label{lbl_example_multiplication_operator_dense_not_bounded}
  Let $x$ be real-valued. We define the {\emph{multiplication by $x$ operator}} on $L^2(\R)$, $M_x\colon \dom{M_x} \to L^2(\R)$, by
  \begin{align*}
    \dom{M_x} \coloneqq  \set{f \in L^2(\R) \colon xf \in L^2(\R)}; \quad
    f(x) \mapsto xf(x).
  \end{align*}
  Then, $M_x$ is a densely-defined operator which is not bounded.
\end{example}
\begin{proof}
  The proof of this example is long but quite simple. We therefore move the proof to Section \eqref{proof_lbl_example_multiplication_operator_dense_not_bounded}, but we describe the rough method here. We can easily see that $\dom{M_x}$ is a subspace via the subspace test. To see that $\dom{M_x}$ is dense, we show that $\dom{M_x}^\perp = \set{0}$, as these two properties are equivalent. This is done by choosing an arbitrary $g$ in $\dom{M_x}^\perp$, showing that $\frac{g(x)}{x^2 +1}$ is in $\dom{M_x}^\perp$, and then using the fact that
  \begin{equation*}
    \ip{\frac{g(x)}{x^2 + 1}, g(x)} = 0
  \end{equation*}
  to see that $g = 0$ almost everywhere. To see that $M_x$ is unbounded, it is easiest to construct a sequence of functions $(f_n)_{n \in \N}$ such that each $f_n$ is in $\dom{M_x}$, but such that $\norm{M_x f_n} \to \infty$ as $n \to \infty$. To do this, we consider the sequence of indicator functions $\left(1_{[n, n+1)} \right)$, which is how {\cite[Lemma 10.7-1]{kreyszig}} does it. For full details, the interested reader can refer to  Section \eqref{proof_lbl_example_multiplication_operator_dense_not_bounded}.
\end{proof}

The multiplication by $x$ operator in $L^2(\R^n)$ also serves as a motivation towards defining our operators on subspaces smaller than the underlying Hilbert space. In Definition \eqref{lbl_def_position_operator}, we will see that this operator describes the position of a quantum particle. However, it is easy to see that it cannot be defined on the entirety of $L^2(\R^n)$. For instance, for any fixed natural number $n$, the function $f \colon \R \to \C$ defined by \[f(x) = \frac{1}{x} 1_{[n, \infty)}(x)\] is in $L^2(\R)$, but $xf(x)$ is not. This is very easy to see, so we omit the calculations here. Due to the importance of the multiplication by $x$ operator, we would quite like to study it, and so we are forced to define it on a subspace of $L^2(\R)$.

\medskip

The following result tells us that our new definition of an operator is consistent with our definition in the bounded case of an operator being defined on the entirety of $\HS$.

\begin{definition}[{\cite[p.4]{konrad}}]
  Let $T \colon \dom{T} \to \HS$ be an operator in $\HS$. Then, an operator $S \colon \dom{S} \to \HS$ is an {\emph{extension of $T$}} if $\dom{T} \subset \dom{S}$ and $Sx = Tx$ for every $x \in \dom{T}$. We say that $S$ is an extension of $T$ to $\dom{S}$, and that $T$ is a domain restriction of $S$ to $\dom{T}$.
\end{definition}

\begin{theorem}[{\cite[Proposition 2.1.11]{analysis_now}}]\label{lbl_thrm_bounded_unique_extension_to_HS}
  Let $T \colon \dom{T} \to \HS$ be a (necessarily densely-defined) operator in $\HS$. If $T$ is continuous, there then exists a unique continuous extension, $R$, to the entirety of $\HS$ such that $\op{R} = \op{T}$.
\end{theorem}
\begin{proof}
  Due to its length and the fact that we include it primarily to justify our new definition of an operator, we move the proof of this result to Section \eqref{proof_lbl_thrm_bounded_unique_extension_to_HS}. To prove this result, we use the briefly described method in the proof of {\cite[Proposition 2.1.11]{analysis_now}} and show the full details. This boils down to using the denseness of the domain of $T$ to construct a well-defined operator $R \colon \HS \to \HS$. As $\dom{T}$ is dense, every vector $x$ in $\HS$ is the limit point of a convergent sequence $(x_n)_{n \in \N}$ in $\dom{T}$. If we define $R$ to be the operator such that $Rx = \lim_{n \to \infty}Tx_n$, then $R$ is well-defined and satisfies our result.
\end{proof}
What this results shows is that every bounded operator defined on the entirety of $\HS$ has a unique domain restriction to a continuous operator defined on a specific dense subspace. This means that our new definition of an operator inside a Hilbert space is compatible with our previous notions of bounded operators.

\medskip

Due to our definition of an operator having a subspace as its domain, we have to constantly be checking what we want to apply our operator to is in its domain. What is even more troublesome is that its domain deeply effects the properties of our operators. We will see this later. For now, we focus on how to define the addition and composition of operators when we have to worry about domain conditions.

\begin{definition}[{\cite[Definitions 13.1]{rudin}}]
  Let $T$ and $S$ be two operators in $\HS$ with respective domains $\dom{T}$ and $\dom{S}$. We define the {\emph{addition}} of $T$ and $S$ as the operator
  \begin{equation*}
    S +  T \colon \dom{S} \cap \dom{T} \to \HS;\,\, (S+T)x \coloneqq Sx + Tx,
  \end{equation*}
  and the {\emph{conjugation}} of $T$ and $S$ as the operator
  \begin{equation*}
    ST \colon \dom{ST} \to \HS; \,\, STx \coloneqq S(T(X)),
  \end{equation*}
  where $\dom{ST} = \set{x \in \dom{T} \colon Tx \in \dom{S}}$.

  \medskip

  We say that $S = T$ if $\dom{S} = \dom{T}$ and $Sx = Tx$ for all $x$ in the shared domain.

  \medskip
  If $\alpha \neq 0$, we define $\alpha T \colon \dom{T} \to \HS$ as the operator $(\alpha T)x \coloneqq \alpha Tx$, and we define and we define $0T \colon \HS \to \HS$ as the operator $(0T)x = 0$.
\end{definition}
\begin{remark}[{\cite[Definitions 13.1]{rudin}}]
  As {\cite[Definitions 13.1]{rudin}} tells us, if $S, T,$ and $R$ are operators in $\HS$, then we have the associativity laws
  \begin{equation*}
      (S + T) + R = S + (T + R) \qquad \text{and} \qquad S(TR) = ST(R).
  \end{equation*}
  We also have the left-distributivity law, $(S + T)R = SR + TR.$ In general, the right-distributivity law can fail as we can have that $\range{T + R}$ is contained in $\dom{S}$ without $\range{T}$ or without $\range{S}$ being contained in $\dom{S}$. These rules are easy to verify, so we omit the details here.
\end{remark}

As we know from bounded operators, operators in general do not need to commute. However, the commution relations of two operators are described via the {\emph{commutator}}.

\begin{definition}[{\cite[p.72]{Hall2013}}]\label{lbl_def_commutator}
  Suppose that $T$ and $S$ are two operators in $\HS$. We define the {\emph{commutator of $T$ and $S$}}, $[T, S] \colon \dom{ST} \cap \dom{TS} \to \HS$, to be the operator in $\HS$ defined by
  \begin{equation*}
    [T, S] \coloneqq TS - ST.
  \end{equation*}
\end{definition}

Commutators come up often in quantum mechanics, and we will have a taster of this in Section (2). Importantly to our later work, commutators have the following properties.

\begin{proposition}[{\cite[Proposition 3.15]{Hall2013}}]\label{lbl_prop_commutator_properties}
  Let $S$, $T$, and $R$ be operators in $\HS$ defined on a common domain such that the range of each operator is contained in this domain. Then,
  \begin{enumerate}[label = (\alph*)]
    \item For all $\alpha \in \C$, $[S, T + \alpha R] = [S, T] + \alpha [S, R]$.
    \item $[S, T] = - [T, S]$.
    \item $[S, TR] = [S, T]R + T[S, R]$.
    \item $\big[ S, [T, R] \big] = \big[ [S, T], R \big] + \big[T, [S, R] \big]$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  As all of our operators are on a common domain and are such that the range of each operator is contained in the domain, each commutator in the above result is defined on the same domain as our original operators. Where these results may hold on domains that do not meet our assumption, one will have to worry about the domain of each commutator in this situation. The verification of this result is therefore just a series of simple calculations from the definition of the commutator. Due to our time constraints, we do not show the details here; the interested reader can find the full calculations in Section \eqref{proof_lbl_prop_commutator_properties}.
\end{proof}

\subsection{Graphs, closed and closable operators, and the closed graph theorem}

\input{sec_unbounded/graphs}

\subsection{The spectrum of a closed operator}

For a bounded operator, we know that its spectrum is very important. It gives us a way to understand how the operator behaves by decomposing the underlying Hilbert space into subspaces where the operator's behaviour is relatively simple and well-understood. Our goal here is to expand the definition of the spectrum to work for unbounded operators. We first define what it actually means for an unbounded operator to be invertible.

\begin{definition}[{\cite[5.1.1]{analysis_now}}]
  Let $T$ be a not necessarily densely-defined injective operator in $\HS$. We define the inverse of $T$ to be the operator \[T^{-1}\colon \range{T} \to \dom{T}\] such that for all $x$ in the domain of $T$, we have that
  \begin{equation*}
    T^{-1}Tx = x.
  \end{equation*}
\end{definition}

\medskip

We now introduce the concept of a {\emph{regular point}} of an operator.

\begin{definition}[{\cite[Definition 2.1, 2.2]{konrad}}]
  Let $T$ be a not necessarily densely-defined operator in $\HS$. We call $\lambda \in \C$ a {\emph{regular point of $T$}} if there exists some positive real-constant, $c_{\lambda} > 0$, such that for all $x$ in the domain of $T$, we have that
  \begin{align*}
    c_{\lambda} \norm{x} \leq \norm{(T - \lambda I)x}.
  \end{align*}
  We define the {\emph{regularity domain of $T$}}, $\pi(T)$, to be the set of regular points of $T$.

  \medskip

  For a regular point $\lambda \in \pi(T)$ of $T$, we call the subspace $\big(\range{T - \lambda I}\big)^\perp$ the  {\emph{deficiency subspace of $T$ at $\lambda$}}, and its dimension, $d_\lambda(T) \coloneqq \text{dim}\big( (\range{T - \lambda I}\big)^\perp \big)$, the {\emph{defect number of $T$ at $\lambda$}}.
\end{definition}
We warn the reader that some authors define regular points as the points of the {\emph{resolvent set}} of an operator; we will introduce this set momentarily. For instance, this is the case in {\cite[Definition 7.2-1]{kreyszig}}, but this is not the case in {\cite[Definition 2.1]{konrad}} or {\cite[Proposition 9.14]{Hall2013}}. Our definition is more general, and we will see the relationships between these alternative definitions shortly in Proposition \eqref{lbl_resolvent_and_regular_point_relation} and in Corollary \eqref{lbl_corollary_sa_op_and_regular_points}.

\medskip

The regular points of an operator have some very nice properties, such as the following result.

\begin{proposition}[{\cite[Proposition 2.1]{konrad}}]\label{lbl_prop_properties_of_regular_points}
  Let $T$ be a not necessarily densely-defined operator in $\HS$ and let $\lambda$ be some complex number. Then,
  \begin{enumerate}[label = (\alph*)]
    \item $\lambda$ is a regular point of $T$ if and only if $T - \lambda I$ has a bounded inverse.
    \item $\pi(T)$ is an open subset of $\C$.
    \item If $T$ is closable and $\lambda$ is a regular point of $T$, we have that
      \begin{enumerate}[label=(\roman*)]
        \item $\overline{\range{T - \lambda I}} = \range{\overline{T} - \lambda I}$
        \item $\pi(T) = \pi(\overline{T})$, and
        \item $d_\lambda(T) = d_\lambda (\overline{T})$.
      \end{enumerate}
    \item If $T$ is closed and $\lambda$ is a regular point, then $\range{T - \lambda I}$ is closed.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Where this result is incredibly useful to us, it is unfortunately very long. Due to our time constraints, we therefore move the proof to Section \eqref{proof_lbl_prop_properties_of_regular_points} for the interested reader. In our work, we will mostly rely on part (a) and part (b) of this result, so we describe the methods for those parts here.

  \medskip

  For the forwards implication of part (a), the inequality in the definition of $\lambda$ being a regular point actually implies that $T - \lambda I$ is injective via the positive-semidefiniteness of the norm. As it is injective, we have a defined inverse operator, which can be shown to be bounded through the the inequality in the definition of $\lambda$ being a regular point. The reverse implication follows by using the definition of the inverse and the operator norm inequality.

  \medskip

  Part (d) follows directly from part (c) and the definition of $T$ being a closed operator.
\end{proof}


We now move on to defining our unbounded operator version of the spectrum and resolvent set of an operator, which mimics the definition for bounded operators defined on the entirety of the Hilbert space.

\begin{definition}[{\cite[Definition 2.3]{konrad}}]\label{lbl_def_spectrum}
  Let $T$ be a not necessarily densely-defined closed operator in $\HS$. The {\emph{resolvent set of $T$}}, $\rho(T)$, is the set
  \begin{align*}
    \rho(T)
    &\coloneqq \big\{\lambda \in \C \colon (T - \lambda I)^{-1} \,\text{exists and} \\ &\qquad\qquad\qquad\text{is a bounded operator defined on the entirety of $\HS$}.\big\} \\
    &=
    \set{\lambda \in \C \colon \ker{T - \lambda I} = \set{0} \,\,\text{and}\,\,\range{T - \lambda I} = \HS}.
  \end{align*}
  If $\lambda \in \rho(T)$, we define the {\emph{resolvent operator}}, $R_\lambda: \HS \to \dom{T - \lambda I}$, as the operator \(R_\lambda = (T - \lambda I)^{-1}.\) Finally, we define the {\emph{spectrum of $T$}} to be the set
  \begin{align*}
    \sigma(T)
    &\coloneqq
    \C\, \backslash \,\rho(T) \\
    &=
    \big\{\lambda \in \C \colon (T - \lambda I)^{-1} \,\text{does not exist as a}\\ &\qquad\qquad\qquad \text{bounded operator defined on the entirety of $\HS$}.\big\}
  \end{align*}
\end{definition}
\begin{remark}\label{lbl_remark_spectrum}
  As the remark in {\cite[p.28]{konrad}} states, the closure of $T$ is not technically necessary; without it, however, we have a trivial case of $\rho(T) = \emptyset$ and $\sigma(T) = \C$. As {\cite[p.28]{konrad}} says, this is as if $\lambda$ is in the resolvent set of $T$, by definition it means that the operator $(T - \lambda I)^{-1}$ is defined everywhere on $\HS$ and is bounded. By the closed graph theorem, Theorem \eqref{lbl_thrm_closed_graph}, this therefore means that $(T - \lambda I)^{-1}$ is a closed operator. However, we will see later in Theorem \eqref{lbl_thrm_densely_defined_and_closability} that an operator with a defined inverse is closed if and only if its inverse is closed. This means that if $T$ is not closed, its resolvent set must be empty, which therefore means that its spectrum is the entirety of $\C$. It thererefore makes sense to impose the condition of our operator being closed as to avoid this trivial case.
\end{remark}

We now see that Proposition \eqref{lbl_prop_properties_of_regular_points} gives us a nice relation between regular points and the resolvent set of an operator.

\begin{proposition}[{\cite[Proposition 2.6]{konrad}}]\label{lbl_resolvent_and_regular_point_relation}
  Let $T$ be a not necessarily densely-defined closed operator in $\HS$. Then,
  \begin{enumerate}[label = (\alph*)]
    \item $\rho(T) = \set{\lambda \in \pi(T) \colon d_\lambda(T) = 0}$.
    \item $\rho(T)$ is an open subset of $\C$ and $\sigma(T)$ is a closed subset of $\C$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  As the proof of {\cite[Proposition 2.6]{konrad}} points out, (a) is an easy consequence of Proposition \eqref{lbl_prop_properties_of_regular_points}. First, suppose that $\lambda$ is in the resolvent set of $T$. Then, we must have that $T - \lambda I$ has a bounded inverse defined on the entirety of $\HS$. By Proposition \eqref{lbl_prop_properties_of_regular_points}(a), this is true if and only if $\lambda$ is a regular point of $T$. As $T - \lambda I$ must be surjective, we have that
  \begin{align*}
    \left( \range{T - \lambda I} \right)^\perp = \HS^\perp = \set{0},
  \end{align*}
  meaning that $d_\lambda(T) = 0$. This gives us our required result of the spectrum being exactly the complex numbers which are regular points of $T$ with the defect number 0.

  \medskip

  We omit the proof for part (b), as it relies on the topological idea of a set being {\emph{locally constant}}. For details, please first see the result and proof of {\cite[2.4]{konrad}} before looking at the proof of {\cite[Proposition 2.6]{konrad}}. We do note, however, that it is quite easy to show part (b) for a class of operator known as the {\emph{self-adjoint operators}}, which we will introduce later. We will prove part (b) for self-adjoint operators in Theorem \eqref{lbl_sa_op_closed_spectrum}.
\end{proof}

\begin{remark}
  By Corollary \eqref{lbl_closed_means_resolvent_function_closed}, it follows that if $T$ is closed and $\lambda$ is in the resolvent set of $T$, then $T - \lambda I$ is also closed.
\end{remark}

The following example shows that unbounded operators may have an empty spectrum. This differs to bounded operators defined on the entirety of the Hilbert space. Recall that, for a bounded interval $I \subset \R$, a function $f \colon I \to \R$ is {\emph{absolutely continuous}} if for every real number, $c$, there exists a function $g \in L^1(I)$ which is integrable on every compact subset of $I$ and is such that we have
\begin{equation*}
  f(x) = f(c) + \int_{c}^{x} g(t)\,\mathrm{d}t.
\end{equation*}
A brief introduction to absolutely continuous functions can be found in {\cite[Chapter 2.7]{teschl}} for the interested reader.

\begin{example}[{\cite[Example 5, Chapter VIII]{reed}}]
  Let $P$ be the operator in $L^2\left( [0, 1] \right)$ defined by
  \begin{align*}
    \dom{P} &= \big\{f \in L^2\left( [0, 1] \right) \colon \text{$f \colon [0,1] \to \C$ is absolutely continuous,}\\ &\qquad\qquad\qquad\qquad\,\, \text{$f' \in L^2\left( [0, 1]\right)$, $f(0) = 0$}\big\}, \\
    P f &= i f'.
  \end{align*}
  The, the spectrum of $P$ is empty. As this is a fairly simple but long verification, we omit the proof here; for details, please see {\cite[Example 5, Chapter VIII]{reed}}.
\end{example}

We end this section with defining the point spectrum of a closed operator.

\begin{definition}[{\cite[Definition 2.4]{konrad}}]
  Let $T$ be a closed operator in $\HS$. The {\emph{point spectrum of $T$}} is defined to be the set
  \begin{equation*}
    \sigma_p(T) \coloneqq \set{\lambda \in \C \colon \,\text{$T - \lambda I$ is not an injective operator}}.
  \end{equation*}
  Any value of the point spectrum is called an {\emph{eigenvalue}} of $T$. If $\lambda$ is an eigenvalue of $T$, we call the set $\ker{T - \lambda I}$ the {\emph{eigenspace}} corresponding to $\lambda$. Any non-zero vector in an eigenspace of $T$ is called an {\emph{eigenvector}} of $T$.
\end{definition}

We note that the majority of Section \eqref{lbl_section_qho} is dedicated to finding the point spectrum of a specific operator of importance in quantum mechanics. We will also find the spectrum and point spectrum of an operator in Example \eqref{lbl_example_multiplication_operator_spectrum}, which will show that some operators do not have any eigenvalues. This is consistent with bounded operators defined on the entirety of $\HS$.

\subsection{Adjoints of an unbounded operator}\label{lbl_sec_adjoints}

Our next step is to work out how we can define the adjoint of an operator in $\HS$. If $S: \HS \to \HS$ is a bounded operator, then the existence of its adjoint is a consequence of the Riesz representation theorem, Theorem \eqref{lbl_thrm_riesz_representation_thrm}. It is natural to try and mimick this in our case of an operator in $\HS$, which we do by following {\cite[Definition 5.1.2]{analysis_now}}.

\medskip

Recall that when we talk about an operator, we said that we normally assume it to be densely-defined. This assumption is necessary for the definition of the adjoint, as it gives us the uniqueness to our definition. Let $T \colon \dom{T} \to \HS$ be an operator in $\HS$. We define the not necessarily densely-defined {\emph{adjoint operator}} $T^* \colon \dom{T^*} \to \HS$ with the domain
\begin{equation*}
  \dom{T^*} \coloneqq \set{y \in \HS \colon x \mapsto \ip{Tx, y} \, \text{is a continuous map}.}
\end{equation*}
A simple application of the subspace test shows that $\dom{T^*}$ is a subspace. As $\dom{T}$ is dense, by Theorem \eqref{lbl_thrm_bounded_unique_extension_to_HS}, the functional $x \mapsto \ip{Tx, y}$ for every $y$ in $\dom{T^*}$ has a unique extension to the entirety of $\HS$. The Riesz representation theorem, Theorem \eqref{lbl_thrm_riesz_representation_thrm}, then tells us that there exists a unique vector $z \in \HS$ such that
\begin{equation*}
  \ip{Tx, y} = \ip{x, z}
\end{equation*}
for all $x \in \dom{T}$ and for all $y \in \dom{T^*}$. We define $T^*$ as the map such that $T^*y = z$. Clearly, without $T$ being densely-defined, we do not have this unique definition of $T^*$, and so we only define the densely-defined operators to have an adjoint. Importantly, the adjoint operator does not have to be densely-defined. We will later see in Theorem \eqref{lbl_thrm_densely_defined_and_closability} that the closable operators are precisely the operators with a densely-defined adjoint.

\begin{theorem}[{\cite[Theorem 13.2]{rudin}}]\label{lbl_thrm_1_4_1}
  Suppose that $T, S$, and $ST$ are operators in $\HS$. Then,
  \begin{enumerate}[label = (\alph*)]
    \item $(ST)^*$ is an extension of $T^* S^*$.
    \item If $S$ is bounded and $\dom{S} = \HS$, then $T^*S^* = (ST)^*$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  This proof is a very important exercise for getting a grasp on how adjoints work for unbounded operators. It is not a result we will rely on, however, so we omit the details here. The full details can be found in Section \eqref{proof_lbl_thrm_1_4_1}, which is recreated from {\cite[Theorem 13.2]{rudin}}. We note that, to show the continuity of the linear functional $x \mapsto \ip{STx, y} = \ip{x, T^*S^*y}$ where $y$ is in the domain of $T^*S^*$, we use the Cauchy-Schwarz inequality to show boundedness. In general, this is a good method to try.
\end{proof}

A very nice fact is that the adjoint of an operator is always closed. A shorter, more elegant proof is given by {\cite[Theorem 13.9]{rudin}}, which we do not use due to it relying on more results.

% \begin{lemma}[\textbf{rudin, 13.7}]\label{lbl_lemma_unitary_op_for_graphs}
%   The operator $V\colon \HS \oplus \HS \to \HS \oplus \HS$ defined by
%   \begin{equation*}
%     V(a,b) = (-b, a)
%   \end{equation*}
%   for all $(a,b) \in \HS \oplus \HS$ is a unitary operator satisfying $V^2 = - I$.
% \end{lemma}
% \begin{proof}
%   We start by observing that $V$ is obviously linear, as for all $\alpha, \beta \in \C$ and for all $(a,b), (c,d) \in \HS \oplus \HS$, we have that
%   \begin{align*}
%     V\big(\alpha(a, b) + \beta(c,d) \big)
%     &=
%     (- \alpha b - \beta d, \alpha a + \beta c) \\
%     &=
%     \alpha( -b,  a) + \beta ( -d,  c) \\
%     &=
%     \alpha V(a,b) + \beta V(c,d).
%   \end{align*}
%   We also easily see that $V$ is bounded, as we also have that
%   \begin{align*}
%     \norm{V(a,b)}_{\HS \oplus \HS}^2
%     &=
%     \norm{(-b, a)}_{\HS \oplus \HS}^2 \\
%     &=
%     \ip{(-b, a), (-b,a)}_{\HS \oplus \HS} \\
%     &=
%     \ip{-b, -b}_{\HS} + \ip{a, a}_{\HS} \\
%     &=
%     \ip{b, b}_{\HS} + \ip{a, a}_{\HS} \qquad \text{by linearity and conjugate-linearity of $\ip{\cdot, \cdot}$} \\
%     &=
%     \ip{a,a}_{\HS} + \ip{b, b}_{\HS} \\
%     &=
%     \ip{(a,b), (a,b)}_{\HS \oplus \HS} \\
%     &=
%     \norm{(a,b)}^2_{\HS \oplus \HS},
%   \end{align*}
%   so $\op{V} = 1$. It is also straight forward to work out the adjoint of $V$, as we have that
%   \begin{align*}
%     \ip{V(a,b), (c,d)}_{\HS \oplus \HS}
%     &=
%     \ip{(-b, a), (c,d)}_{\HS \oplus \HS} \\
%     &=
%     \ip{a, d}_{\HS}  - \ip{b, c}_{\HS} \\
%     &=
%     \ip{a, d}_{\HS}  + \ip{b, -c}_{\HS} \\
%     &=
%     \ip{(a, b), (d, -c)}_{\HS}.
%   \end{align*}
%   As $(d, -c)$ must be the unique vector satisfying the above equation, we therefore see that $V^*\colon \HS \oplus \HS \to \HS \oplus \HS$ is defined by
%   \begin{equation*}
%     V^*(a,b) = (b, -a)
%   \end{equation*}
%   for all $a, b \in \HS \oplus \HS$. We see that it is unitary, as
%   \begin{align*}
%     VV^*(a,b) &= V(b, -a) = (a,b), \,\, \text{and} \\
%     V^*V(a,b) &= V^*(-b, a) = (a,b),
%   \end{align*}
%   so $VV^* = I = V^*V$. Finally, we see that
%   \begin{align*}
%     V^2(a,b) = V(-b, a) = (-a, -b) = -I(a,b),
%   \end{align*}
%   so $V^2 = -I$.
% \end{proof}
% \begin{remark}[\textbf{rudin, 13.7}]
%   As $V^2 = -I$, for any subspace $X \subset \HS \oplus \HS$, we clearly have that $V^2 M = M$, as all subspaces include the negative multiples of every vector.
% \end{remark}
%
% \begin{theorem}[\textbf{rudin, theorem 13.8}]
%   Let $T$ be an operator in $\HS$ and let $V \colon \HS \oplus \HS \to \HS \oplus \HS$ be the unitary operator defined in Lemma \eqref{lbl_lemma_unitary_op_for_graphs}. Then,
%   \begin{equation*}
%     \G(T^*) = \big( V\G(T) \big)^\perp.
%   \end{equation*}
% \end{theorem}
% \begin{proof}
%   {\large \textbf{We recreate this proof from \textbf{rudin, 13.8}}}
%
%   Let $y \in \dom{T^*}$. Then, $(y, T^*y) \in \G(T^*)$ by the definition of $\G(T^*)$. Then, for all $x \in \dom{T}$, we have that
%   \begin{align*}
%     \ip{Tx, y}_{\HS} = \ip{x, T^*y}_{\HS},
%   \end{align*}
%   meaning that
%   \begin{align*}
%     - \ip{Tx, y}_{\HS} + \ip{x, T^*y}_{\HS}= 0.
%   \end{align*}
%   Therefore, by linearity of the inner product and the definition of $\ip{\cdot, \cdot}_{\HS \oplus \HS}$,
%   \begin{align*}
%     \ip{(-Tx, x), (y,T^*y)}_{\HS\oplus\HS} = 0.
%   \end{align*}
%   Now, $(-Tx, x)$ is clearly an element of $V \G(T)$. As our choice of $x$ in the domain of $T$ was arbitrary, this is then clearly only true if $(y, T^*y)$ is orthogonal to every $(-Tx, x) \in V\G(T)$; therefore,$(y, T^*y) \in \big( V\G(T) \big)^\perp$.
%
%   \medskip
%
%   Now suppose that $(y, z) \in \big( V\G(T) \big)^\perp$. Then, for all $x \in \dom{T}$, we have that $(-Tx, x) \in V\G(T)$, so
%   \begin{align*}
%     0
%     &=
%     \ip{(-Tx, x), (y, z)}_{\HS \oplus \HS} \\
%     &=
%     \ip{x, z}_{\HS} - \ip{Tx, y}_{\HS}.
%   \end{align*}
%   By re-arranging and applying the Cauchy-Schwarz inequality, we have that
%   \begin{align*}
%     \ip{Tx, y}_{\HS} = \ip{x, z}_{\HS} \leq \norm{x}_{\HS} \norm{z}_{\HS},
%   \end{align*}
%   meaning that the linear functional $x \mapsto \ip{Tx, y}_{\HS}$ is bounded, and therefore $y \in \dom{T^*}$. This gives us that
%   \begin{align*}
%     \ip{x, z}_{\HS} = \ip{x, T^*y},
%   \end{align*}
%   so $z = T^*y$ as $T^*y$ has a unique value. Therefore, $(y, z) = (y, T^*y)$, so $(y, z) \in V\G(T^*)$. By double inclusion, we see that $V\G(T^*) = \big( V\G(T)\big)^\perp$.
% \end{proof}

\begin{proposition}[{\cite[Proposition 9.8]{Hall2013}}]\label{lbl_prop_adjoint_closed}
  If $T$ is an operator in $\HS$, then $T^*$ is closed; that is, $\G(T^*)$ is a closed set.
\end{proposition}
\begin{proof}
  To prove this, we follow the method used in the proof of {\cite[Proposition 9.8]{Hall2013}}. Suppose that $(x_n, y_n)_{n \in \N}$ is some convergent sequence in $\G(T^*)$. We must then have that $(x_n)_{n \in \N}$ converges to some $x \in \HS$, that $(y_n)_{n \in \N}$ converges to some $y \in \HS$, and that $y_n = T^*x_n$ for every $n \in \N$. Then, for any $z \in \dom{T}$, we have that
  \begin{align*}
    \ip{Tz, x}
    =
    \ip{Tz, \lim_{n \to \infty} x_n}
    &=
    \lim_{n \to \infty} \ip{Tz, x_n} \\
    &=
    \lim_{n \to \infty} \ip{z, T^* x_n} \\
    &=
    \ip{z, y} \\
    &\leq
    \norm{z} \norm{y} \,\,\text{by the Cauchy-Schwarz inequality.}
  \end{align*}
  Therefore, the linear functional $z \mapsto \ip{Tz, x}$ is bounded, so it is continuous and therefore $x$ is in the domain of $T^*$. As $T^*x$ has a unique value, we must have that $T^*x = y$. Therefore, any convergent sequence in $\G(T^*)$ must have its limit point in $\G(T^*)$, and so $\G(T^*)$ is closed.
\end{proof}

As we might expect from our experience with bounded operators, adjoints of unbounded operators follow some nice algebraic properties.

\begin{proposition}[{\cite[Proposition 1.6]{konrad}}]\label{lbl_prop_properties_of_adjoints}
  Let $\HS$ be a separable Hilbert space. Suppose that $T$ is a densely-defined operator in $\HS$ and that $S$ is a not necessarily densely-defined operator in $\HS$. Then,
  \begin{enumerate}[label = (\alph*)]
    \item $\ker{T^*} = \range{T}^\perp$.
    \item If $T^*$ is densely-defined, we have that $T \subset (T^*)^*$.
    \item If $T \subset S$, then $S^* \subset T^*$.
    \item For any scalar $\alpha \in \C$, we have that $(\alpha T)^* = \conjugate{\alpha} T^*$.
    \item If $T+S$ is densely-defined, then $T^* + S^* \subset (T + S)^*$.
    \item If $S$ is bounded and defined on the entirety of $\HS$, then $(T + S)^* = T^* + S^*$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Due to its simplicity, length, and similarity to the case of a bounded operator defined on the entirety of $\HS$, we omit this proof. The interested reader can see the details in the proof of {\cite[Proposition 1.6]{konrad}}.
\end{proof}

We also have the following useful relations via the adjoint between a densely-defined operator and its closability.

\begin{theorem}[{\cite[Theorem 1.8]{konrad}}]\label{lbl_thrm_densely_defined_and_closability}
  Let $T$ be a densely-defined operator in $\HS$. Then,
  \begin{enumerate}[label = (\alph*)]
    \item $T$ is a closable operator if and only if $\dom{T^*}$ is dense. If $T$ is closable, then $\left( \overline{T} \right)^* = T^*$ and $\overline{T} = (T^*)^*$
    \item $T$ is closed if and only if $T = (T^*)^*$.
    \item If $T$ is injective with dense range, then $T^*$ is invertible with $(T^*)^{-1} = \left( T^{-1} \right)^*$.
    \item If $T$ is injective and closable, then $T^{-1}$ is closable if and only if $\overline{T}$ is injective; in this case, we also have that $\left( \overline{T} \right)^{-1} = \overline{T^{-1}}$.
    \item If $T$ is invertible, then $T$ is closed if and only if $T^{-1}$ is closed.
  \end{enumerate}
\end{theorem}
\begin{proof}
  Due to its simplicity, length, and similarity to the case of a bounded operator defined on the entirety of $\HS$, we omit this proof. The interested reader can see the details in the proof of {\cite[Theorem 1.8]{konrad}}, which relies on {\cite[Lemma 1.10]{konrad}}.
\end{proof}

Theorem \eqref{lbl_thrm_densely_defined_and_closability} is useful as it can provide potential shortcuts to verifying if an operator is closed. For instance, we can use it to verify that a natural extension of the operator introduced in Example \eqref{lbl_example_kreyzsig_not_closed_operator} is closed.

\begin{example}[{\cite[Problem 5, Chapter 10.3]{kreyszig}}]\label{lbl_example_kreyzsig_closed_operator}
  Let $T$ be the operator in $\ell^2$ introduced in Example \eqref{lbl_example_kreyzsig_not_closed_operator}, which was defined by
  \begin{align*}
    \dom{T} &= \set{x \in \ell^2 \colon \text{$x$ has finitely many non-zero elements}}, \\
    Tx &= (jx_j)_{j \in \N}.
  \end{align*}
  In Example \eqref{lbl_example_kreyzsig_not_closed_operator}, we showed that $T$ is not a closed operator. However, the operator $S$ in $\ell^2$ given by
  \begin{align*}
    \dom{S} &= \set{x \in \ell^2 \colon (jx_j)_{j \in \N} \in \ell^2}, \\
    Sx &= (jx_j)_{j \in \N}
  \end{align*}
  is a closed extension of $T$, meaning that $T$ is closable.
\end{example}
\begin{proof}
  The proof of this example is fairly simple but long, so we move it to Section \eqref{proof_lbl_example_kreyzsig_closed_operator} due to our time constraints. We briefly describe the method of the proof here.

  \medskip

  We first need to show that $\dom{S}$ is a subspace of $\ell^2$, which is most easily done via the subspace test. Now, it is easy to see that $\dom{T}$ is a subspace of $\dom{S}$ by comparing their definitions. The proof of Example \eqref{lbl_example_kreyzsig_not_closed_operator} shows that $\dom{T}$ is dense in $\ell^2$, which implies that $\dom{S}$ is dense. As $S$ and $T$ have the same defining equation and $\dom{T}$ is a subspace of $\dom{S}$, $S$ is an extension of $T$. As is done in the solution to {\cite[Problem 5, Chapter 10.3]{kreyszig}},  which is given in {\cite[p.667]{kreyszig}}, to see that $S$ is closed we note that it is the inverse of a bounded operator defined on the entirety of $\HS$. By the closed graph theorem, Theorem \eqref{lbl_thrm_closed_graph}, the inverse of $S$ must therefore be closed. By Theorem \eqref{lbl_thrm_densely_defined_and_closability}, $S$ is therefore closed, making it a closed extension of $T$. We encourage the reader to see the full details in Section \eqref{proof_lbl_example_kreyzsig_closed_operator}.
\end{proof}

Theorem \eqref{lbl_thrm_densely_defined_and_closability} also serves as a lemma for us to relate the spectrum and resolvent set of a densely-defined closed operator to those of its adjoint. This result mirrors the bounded operator case. It also provides us with the tools to see that the boundedness requirement in our definition of the resolvent set is not actually necessary.

\begin{proposition}[{\cite[Proposition 2.7]{konrad}}]\label{lbl_prop_spectrum_and_adjoint}
  Let $T$ be a closed operator in $\HS$. Then,
    \begin{enumerate}[label = (\alph*)]
      \item $\rho(T)$ is the set of complex numbers such that $T - \lambda I \colon \dom{T} \to \HS$ is bijective.
      \item If $T$ is densely-defined, then
      \begin{enumerate}[label = (\roman*)]
        \item $\lambda \in \rho(T)$ if and only if $\conjugate{\lambda} \in \rho(T^*)$.
        \item $\lambda \in \sigma(T)$  if and only if $\conjugate{\lambda} \in \sigma(T^*)$.
      \end{enumerate}
  \end{enumerate}
\end{proposition}
\begin{proof}
  As might be expected, the proof to this is very similar to the proof of the result in the case of a bounded operator defined on the entirety of $\HS$. The only difference is that we need to take care with domains and that we have to consciously take into account that our operator is closed. It is, however, an important proof for getting used to how unbounded operators behave. We therefore move this proof to Section \eqref{proof_lbl_prop_spectrum_and_adjoint}, which is a recreation of the proof given in {\cite[Proposition 2.7]{konrad}}.
\end{proof}

\begin{remark}
  As {\cite[p.30]{konrad}} points out, Proposition \eqref{lbl_prop_spectrum_and_adjoint} tells us that the values of $\lambda$ in the resolvent set are precisely the values that make $T - \lambda I$ bijective. This means that an element $\mu$ of the spectrum of $T$ are exactly the values which make $T - \mu I$ either not injective or not surjective. It therefore follows that the point spectrum is a subset of the spectrum of an operator.
\end{remark}

\subsection{Symmetric and self-adjoint operators}

Now, we know that for bounded operators defined on the entirety of $\HS$, there are some which are equal to their adjoint. It is natural to wish to have the same idea for unbounded operators. However, it follows by our definition of the adjoint that there is a class of operator inbetween non-self-adjoint operators and self-adjoint operators.

\begin{definition}[{\cite[Definition 13.3]{rudin}}]
  A not necessarily densely-defined operator $T: \dom{T} \to \HS$ is called {\emph{symmetric}} if for all $x \in \dom{T}$ and $y \in \dom{T}$, we have that
  \begin{equation*}
    \ip{Tx, y} = \ip{x, Ty}.
  \end{equation*}
  If $T$ is densely-defined and $T = T^*$, then we say that it is self-adjoint.
\end{definition}

It follows that every self-adjoint operator is symmetric. However, not every symmetric operator is self-adjoint. This is not a pathology, and many symmetric operators are not self-adjoint. We will see a very nice example of this in Example \eqref{lbl_example_sa_esa_not_esa}.

\medskip

It turns out that we already have the tools to prove nice results about these two types of operator. For instance, a very nice property is that the addition of two symmetric operators is another symmetric operator.

\begin{proposition}
  If $T$ and $S$ are two symmetric operators in $\HS$, then $S+T$ is also a symmetric operator.
\end{proposition}
\begin{proof}
  Let $x$ and $y$ be two elements of $\dom{S+T}$. Clearly, we must have that $x, y \in \dom{S}$ and $x, y \in \dom{T}$. We then easily see that
  \begin{align*}
    \ip{(S + T)x, y}
    &=
    \ip{Sx, y} + \ip{Tx, y}
    =
    \ip{x, Sy} + \ip{x, Ty}
    =
    \ip{x, (S + T)y},
  \end{align*}
  so $S+T$ is also a symmetric operator.
\end{proof}
\begin{remark}\label{lbl_remark_failure_of_addition_of_sa_dense_domains}
  We note that this proof relies heavily on the fact that we do not require our symmetric operators to be densely-defined. Indeed, just because $\dom{T}$ and $\dom{S}$ are densely-defined does not mean that their intersection, $\dom{S+T}$, is. This gives us a possible case for when the sum of self-adjoint operators not being self-adjoint.
\end{remark}

If an operator $T$ is densely-defined, then it being symmetric is equivalent to $T^*$ being an extension of $T$.

\begin{proposition}[{\cite[Proposition 9.4]{Hall2013}}]\label{lbl_prop_sym_iff_adjoint_is_extension}
  An operator $T$ in $\HS$ is symmetric if and only if $T^*$ is an extension of $T$.
\end{proposition}
\begin{proof}
    We take this proof from {\cite[Proposition 9.4]{Hall2013}}. Suppose that $T$ is symmetric. For all $x, y \in \dom{T}$, by the Cauchy-Schwarz inequality we have that
    \begin{align*}
      \abs{\ip{Tx, y}}
      =
      \abs{\ip{x, Ty}}
      \leq
      \norm{x} \norm{Ty}.
    \end{align*}
    We therefore have that the linear functional $x \mapsto \ip{Tx, y}$ is bounded. As boundedness is equivalent to continuity, by definition of $T^*$ we have that $y \in \dom{T^*}$, so $\dom{T} \subset \dom{T^*}$. Now, as $
      \ip{Tx, y} = \ip{x, Ty}
      $ by the symmetry  of $T$, clearly the unique vector $T^*x$ which satisfies
    \begin{equation*}
      \ip{x, Ty} = \ip{T^*x, y}
    \end{equation*}
    must be $Tx$. Therefore, $T^*x = Tx$ for all $x \in \dom{T}$, giving us the final requirement for $T^*$ to be an extension of $T$.

    \medskip

    Now suppose that $T^*$ is an extension of $T$. Then, for all $x, y \in \dom{T} \subset \dom{T^*}$, as $T^*$ is an extension of $T$ we have that
    \begin{align*}
      \ip{Tx, y}
      =
      \ip{x, T^*y}
      =
      \ip{x, Ty},
    \end{align*}
    so $T$ is symmetric.
\end{proof}

Armed with our previous result, we return to the first example of an operator we saw; namely, the multiplication by $x$ operator in $L^2(\R)$. We see here that it is self-adjoint on the domain we have seen it defined on before. In Proposition \eqref{lbl_prop_position_momentum_esa_on_S_R}, we will see that by restricting the domain slightly, it no longer stays self-adjoint. This is one of the reasons why we must always be conscious of the domain our operator is defined on; its properties can be inherently linked to its domain.

\begin{example}[{\cite[Theorem 10.7-2]{kreyszig}}]\label{lbl_example_multiplication_operator_sa}
  Recall that in Example \eqref{lbl_example_multiplication_operator_dense_not_bounded} that, for some real-valued $x$, we introduced the multiplication by $x$ operator $M_x$ in $L^2(\R)$, defined by
  \begin{align*}
    \dom{M_x} &\coloneqq  \set{f \in L^2(\R) \colon xf \in L^2(\R)}, \\
    f(x) &\mapsto xf(x).
  \end{align*}
  In this example, we showed that $M_x$ on this domain was densely-defined (meaning that an adjoint is defined) and not bounded. $M_x$ is also self-adjoint on this domain.
\end{example}
\begin{proof}
  The proof of this example is quite simple, but we move it to Section \eqref{proof_lbl_example_multiplication_operator_sa} due to our time constraints. The method is to first verify that $M_x$ is symmetric on this domain, which follows trivially from $x$ being a real number implying that $x = \conjugate{x}$. By Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension}, this means that $M_x^*$ is an extension of $M_x$. We therefore just need to verify that $\dom{M_x^*}$ is equal to $\dom{M_x}$. This is done by using the fact that
  \begin{equation*}
    \ip{M_x f, h} = \ip{f, M_x^* h}
  \end{equation*}
  for all $f$ in $\dom{M_x}$ and for all $h$ in $\dom{M_x^*}$. By subtracting the right-hand side and then constructing a specific function, we can then show that $M_x^* h = M_x h$ for all $h$ in $\dom{M_x^*}$, meaning that the domains of $M_x$ and $M_x^*$ are equal by remembering that $M_x^*$ is an extension. The interested reader can see the full details in Section \eqref{proof_lbl_example_multiplication_operator_sa}, which is taken from the proof of {\cite[Theorem 10.7-2]{kreyszig}} and is shown in full detail.
\end{proof}

\begin{remark}
  {\cite[Proposition 9.30]{Hall2013}} shows that we can actually define a more general multiplication operator in $L^2(\R^n)$ which is self-adjoint on an analogously defined domain. If $f \colon \R^n \to \R$ is a measurable function, we define the {\emph{mutliplication by $f$ operator in $L^2(\R^n)$}}, $M_f \colon \dom{M_f} \to L^2(\R^n)$, by
  \begin{align*}
    \dom{M_f} &\coloneqq  \set{g \in L^2(\R^n) \colon f(x)g(x) \in L^2(\R^n)}, \\
    g(x) &\mapsto f(x)g(x).
  \end{align*}
  This multiplication operator $M_f$ is still densely-defined and is self-adjoint on this domain for $M_f$. We omit the proof here, as for our purposes the multiplication by $x$ operator is good enough and also as the method of the proof is virtually the same. The full details of the proof can be found in {\cite[Proposition 9.30]{Hall2013}}.
\end{remark}

Our first major result motivates why we define unbounded operators on a subset of the underlying Hilbert space rather than the entire space. This relies on the following corollary of Proposition \eqref{lbl_prop_adjoint_closed}, which told us that the adjoint of an operator is closed.

\begin{corollary}[{\cite[Proposition 9.8]{Hall2013}}]\label{lbl_prop_symmetric_op_closable}
  Let $T$ be a symmetric operator in $\HS$. Then, $T$ is closable.
\end{corollary}
\begin{proof}
  As the proof of {\cite[Proposition 9.8]{Hall2013}} points out, this is a basic corollary of the adjoint of an operator being closed, which was shown in Proposition \eqref{lbl_prop_adjoint_closed}. If $T$ is symmetric, then, by Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension}, its adjoint is an extension of $T$. By Proposition \eqref{lbl_prop_adjoint_closed}, the adjoint of an operator is closed; therefore, $T$ is closable.
\end{proof}

\begin{corollary}[{\cite[Corollary 9.9]{Hall2013}}]\label{lbl_corollary_sym_on_H_bounded}
  If $T$ is a symmetric operator defined on the entirety of $\HS$, then it is a bounded operator.
\end{corollary}
\begin{proof}
  As the proof of {\cite[Proposition 9.9]{Hall2013}} observes, this is a simple consequence of Corollary \eqref{lbl_prop_symmetric_op_closable}. If $T$ is a symmetric operator, then by Corollary \eqref{lbl_prop_symmetric_op_closable} it has a closable extension; namely, its adjoint operator $T^*$. However, we have that $\dom{T} = \HS$, so it follows that $T$ is closed as well due to $T^*$ being an extension of $T$. Specifically, this is the consequence of $\dom{T^*} = \HS$ and that $T^* = T$ on the entirety of $\dom{T} = \HS$. This means that $T$ is a closed operator defined on the entirety of $\HS$; therefore, by the closed graph theorem, Theorem \eqref{lbl_thrm_closed_graph}, $T$ must be bounded.
\end{proof}

Where this result is quite simple, it is a major motivation for our condition that an unbounded operator is defined on a subset of $\HS$. Specifically, a self-adjoint operator is not bounded if and only if it is not defined on the entirety of its underlying Hilbert space. The reverse implication is the converse of Corollary \eqref{lbl_corollary_sym_on_H_bounded}; the forward implication is the converse is the closed graph theorem, Theorem \eqref{lbl_thrm_closed_graph}, combined with the adjoint always being closed, which comes from Corollary \eqref{lbl_prop_symmetric_op_closable} and the fact that every self-adjoint operator is symmetric.

\medskip

A valid question to now ask is why should we care about not bounded self-adjoint operators, and not just accept that any self-adjoint operator must be bounded? It turns out that, apart from not bounded self-adjoint operators being an interesting object to study, that they are a vital ingredient in the mathematical formulation of quantum physics. We will see why this is later in Section \eqref{lbl_section_qm_introduction}.

\medskip


As we might expect, we now see that a surjective symmetric operator is self-adjoint.

\begin{proposition}[{\cite[Chapter 41 Theorem 1]{glazman}}]\label{lbl_prop_sym_op_with_range_H}
  If $T$ is a symmetric operator in $\HS$ with $\range{T} = \HS$, then $T$ is self-adjoint.
\end{proposition}
\begin{proof}
  We recreate this proof from the proof of {\cite[Chapter 41 Theorem 1]{glazman}}. Let $y \in \dom{T^*}$. As $T^*y \in \HS$ and $\range{T} = \HS$, there must be some vector $z \in \dom{T}$ such that $Tz = T^*y$. Therefore, for any $x \in \dom{T}$, we have that
  \begin{align*}
    \ip{Tx, y}
    &=
    \ip{x, T^* y}
    =
    \ip{x, Tz}
    =
    \ip{Tx, z}.
  \end{align*}
  As $\range{T} = \HS$, this is true if and only if $z = y$. Therefore, $y \in \dom{T}$, so $\dom{T^*} \subset \dom{T}$. As $T \subset T^*$ and $\dom{T^*} \subset \dom{T}$, this means that $T = T^*$, so $T$ is self-adjoint as required.
\end{proof}

It turns out that we have enough tools to discover properties of the eigenvalues of symmetric operators. We note that these hold for self-adjoint operators, as every self-adjoint operator is a symmetric operator. We also note that these properties mirror the properties of self-adjoint bounded operators, as we might expect.

\begin{proposition}[{\cite[Chapter 41, Theorem 2]{glazman}}]\label{lbl_prop_sym_ops_real_eigenvalues}
  If $T$ is a symmetric operator in $\HS$, then all of its eigenvalues are real-valued.
\end{proposition}
\begin{proof}
  The proof for this result is virtually the same as the proof for the case of a self-adjoint bounded operator defined on the entirety of $\HS$, which is shown in Remark \eqref{lbl_remark_sa_op_real_eigenvalues}. To prove this result, we just take an eigenvector $v$ with corresponding eigenvalue $\lambda$, and we then consider the experssion $\lambda\ip{v,v}$. This is the method {\cite[Chapter 41, Theorem 2]{glazman}} employs. Due to this simplicity, we shift the proof to Section \eqref{proof_lbl_prop_sym_ops_real_eigenvalues}.
\end{proof}

\begin{proposition}[{\cite[Chapter 41, Theorem 3]{glazman}}]\label{lbl_prop_sym_op_eigenvalues_orthogonal}
  Let $T$ be a symmetric operator in $\HS$ with distinct eigenvalues $\lambda_1$ and $\lambda_2$. If $v_1$ is an eigenvalue of $T$ corresponding to $\lambda_1$ and $v_2$ is an eigenvalue of $T$ corresponding to $\lambda_2$, then $v_1$ and $v_2$ are orthogonal.
\end{proposition}
\begin{proof}
  This proof is also virtually the same to the proof in the case of a bounded self-adjoint operator defined on the entirety of $\HS$, which again is argued for in Remark \eqref{lbl_remark_sa_op_real_eigenvalues}. The method of the proof is to manipulate the expression $\lambda_1\ip{v_1, v_2}$. We therefore shift the proof of this result to Section \eqref{proof_lbl_prop_sym_op_eigenvalues_orthogonal}, which uses the same method as {\cite[Chapter 41, Theorem 3]{glazman}}.
\end{proof}

Symmetric operators' spectral properties do not completely mirror the spectral properties of bounded self-adjoint operators, however. For instance, {\cite[Corollary 3.14]{konrad}} tells us that a closed symmetric operator is self-adjoint if and only if its spectrum is contained in the real numbers. We omit the proof of the reverse implication details here, as we do not need it for our future work; however, the full proof can be found in terms of the resolvent set in {\cite[Proposition 3.13]{konrad}}

\begin{proposition}[{\cite[Theorem 9.17]{Hall2013}}]\label{lbl_sa_operator_real_spectrum}
  Let $T$ be a self-adjoint operator in $\HS$. Then, the spectrum of $T$ is real.
\end{proposition}
\begin{proof}
  We recreate this theorem from {\cite[Theorem 9.17]{Hall2013}}. Let $\lambda = a + ib$ be some complex number, where $a$ and $b$ are real with $b$ being non-zero. For all $x \in \dom{T}$, we then see that, by the linearity and conjugate-linearity of the inner product, that
  \begin{align*}
    \norm{(T - \lambda I)x}^2
    &=
    \ip{(T - aI - ibI)x, (T - aI - ibI)x} \\
    &=
    \ip{(T - aI)x, (T - aI)x} + ib\ip{(T - aI)x, x} - ib \ip{x, (T - aI)x}\\&\qquad + b^2 \ip{x,x} \\
    &=
    \norm{(T - aI)x}^2 + b^2\norm{x}^2 + ib(x, (T - aI)x) - ib \left( \ip{x, Tx} - a\ip{x, Ix} \right) \\
    &=
    \norm{(T - aI)x}^2 + b^2\norm{x}^2 + ib(x, (T - aI)x) - ib\ip{(T - aI)x, x} \\&\qquad\qquad\qquad\qquad\qquad\qquad\qquad \text{by the symmetry of $T$ and $I$}\\
    &=
    \norm{(T - aI)x}^2 + b^2\norm{x}^2 \\
    &\geq
    b^2\norm{x}^2.
  \end{align*}
  Therefore, we have that $
    b\norm{x} \leq \norm{(T - \lambda I)x}
  $ for all $x \in \dom{T}$; in other words, $b = \text{im}(\lambda)$ is a regular point of $T$. By positive-definiteness of the norm, we therefore have that $T - \lambda I$ is injective, as $(T - \lambda I)x = 0$ if and only if $\norm{(T - \lambda I)x} = 0$ if and only if (by our above equation) $\norm{x} = 0$ if and only if $x = 0$. As $T - \lambda I$ is injective, its inverse $(T - \lambda I)^{-1}: \range{T} \to \dom{T}$ exists. Now, by Proposition \eqref{lbl_prop_properties_of_adjoints}(a) and (f), as $I$ is bounded, we have that
  \begin{align*}
    \range{T - \lambda I}^\perp
    =
    \ker{(T - \lambda I)^*}
    =
    \ker{T^* - \conjugate{\lambda}I}
    =
    \ker{T - \conjugate{\lambda}I}.
  \end{align*}
  Now, as $\text{im}(\conjugate{\lambda})$ is still non-zero, we can repeat the above steps to see that
  \begin{equation*}
    b\norm{x} \leq \norm{(T - \conjugate{\lambda} I)x},
  \end{equation*}
  which again implies that $T - \conjugate{\lambda}I$ is injective. Therefore, $\range{T - \conjugate{\lambda} I}^\perp$ is the trivial set. This is true if and only if $\range{\conjugate{\lambda}}$ is dense. Now, as $T$ is self-adjoint, it is closed by Proposition \eqref{lbl_prop_adjoint_closed}. By Proposition \eqref{lbl_prop_properties_of_regular_points}, we therefore have that $\range{T - \lambda I}$ is closed. As $\range{T - \lambda I}$ is closed and dense, we therefore have that $\range{T - \lambda I}$ is the entirety of $\HS$, as the closure of a dense subset is the entire space. Therefore, we have that $(T - \lambda I)^{-1}$ is defined on the entirety of $\HS$. It also must be closed by Theorem \eqref{lbl_thrm_densely_defined_and_closability}(e), as $T - \lambda I$ is closed by Corollary \eqref{lbl_closed_means_resolvent_function_closed}. As $(T - \lambda I)^{-1}$ is a closed operator defined on the entirety of $\HS$, by the closed graph theorem, Theorem \eqref{lbl_thrm_closed_graph}, it is bounded. This implies that $\lambda$ is in the resolvent set of $T$. As $\lambda$ is any arbitrary non-real complex number, this implies that the spectrum of $T$ is contained in $\R$.
\end{proof}

Our previous result of a spectrum being real-valued is very valuable, as it allows us to cut out a lot of work. For instance, consider our previous example of the multiplication by $x$ operator in $L^2(\R)$, $M_x$. As we showed in Proposition \eqref{lbl_prop_adjoint_closed}, the adjoint of an operator is always a closed operator. We also saw in Example \eqref{lbl_example_multiplication_operator_sa} that $M_x$ is self-adjoint on the domain we equipped it with there. Therefore, it is also a closed symmetric operator and it has a defined spectrum. By our previous result, this spectrum must be contained in $\R$. An easy calculation shows that the spectrum of $M_x$ on this domain is in fact the entirety of $\R$.

\begin{example}[{\cite[Theorem 10.7-3]{kreyszig}}]\label{lbl_example_multiplication_operator_spectrum}
  For some real-valued $x$, the multiplication by $x$ operator $M_x \colon \dom{M_x} \to L^2(\R)$, defined by
  \begin{align*}
    \dom{M_x} \coloneqq  \set{f \in L^2(\R) \colon xf \in L^2(\R)}; \quad
    f(x) \mapsto xf(x).
  \end{align*}
  On this domain, $M_x$ has no eigenvalues and the spectrum of $M_x$ is the entirety of $\R$.
\end{example}
\begin{proof}
  The proof of this example is very insightful. It is also long, so we are forced to move it to Section \eqref{proof_lbl_example_multiplication_operator_spectrum} due to our time constraints. We briefly describe the method of the proof here.

  \medskip

  The argument that $M_x$ has no eigenvalues is the standard argument. We assume that it has an eigenvector with corresponding eigenvalue, and then show that this implies that the eigenvector is a function that is zero almost everywhere. This is a contradiction, so $M_x$ has no eigenvalues. Importantly, that means that $M_x - \lambda I$ for $\lambda \in \C$ is injective, and therefore has a defined inverse.

  \medskip

  To see that the spectrum of $M_x$ is the entirety of $\R$, we first remember that Example $\eqref{lbl_example_multiplication_operator_sa}$ showed that $M_x$ is symmetric on this domain, so Proposition \eqref{lbl_sa_operator_real_spectrum} tells us that $\sigma(M_x)$ is contained in $\R$. We therefore allow $\lambda$ to be any real number. If we consider the sequence of indicator functions $\left(1_{[\lambda - 1/n,\, \lambda + 1/n]} \right)_{n \in \N}$ and then normalise each term of this sequence,  we get that the image of this normalied sequence under $M_x - \lambda I$ is bounded. By constructing a scaled sequence from this normalised sequence, we can show that the $(M_x - \lambda I)^{-1}$ is not bounded. This means that any real number $\lambda$ is in the spectrum of $M_x$.

  \medskip

  The reader is encouraged to see the full details in Section \eqref{proof_lbl_example_multiplication_operator_spectrum}.
\end{proof}

Recall that in Proposition \eqref{lbl_resolvent_and_regular_point_relation}, we learned that the resolvent set of a general closed operator is made up precisely of the regular points of the operator who have a deficiency number of 0. It turns out that for a self-adjoint operator, every regular point has a deficiency number of 0, meaning that every regular point is in the spectrum.

\begin{corollary}[{\cite[Proposition 3.10]{konrad}}]\label{lbl_corollary_sa_op_and_regular_points}
  Let $T$ be a self-adjoint operator in $\HS$. Then, the following are equivalent:
  \begin{enumerate}[label = (\alph*)]
    \item $\lambda$ is in the resolvent set of $T$.
    \item $\lambda$ is a regular point of $T$.
    \item $\range{T - \lambda I} = \HS$ and $d_\lambda (T) = 0$.
  \end{enumerate}
\end{corollary}
\begin{proof}
  This result is a very interesting property of the resolvent set of self-adjoint operators, and we will make use of it a few times. It is, however, quite long; therefore, due to our time constraints, we shift the proof of this to Section \eqref{proof_lbl_corollary_sa_op_and_regular_points}. The proof we provide is a recreation of the proof provided in {\cite[Proposition 3.10]{konrad}}. The method is relatively simple, and we summarise it here. Firstly, notice that part (b) follows from part (a) directly from Proposition \eqref{lbl_resolvent_and_regular_point_relation}.

  \medskip

  To see that part (c) follows from part (b), we first consider if $\lambda$ is a complex number that is nonn-real. As the spectrum of $T$ is contained in the real numbers by Proposition \eqref{lbl_sa_operator_real_spectrum}, this means that $\lambda$ is in the resolvent set of $T$. By taking into account the self-adjointness of $T$ and the relation between the kernel and the range of an operator given in Proposition \eqref{lbl_prop_properties_of_adjoints}(a), the result then follows. If we then consider $\lambda$ to be real, the inequality we get from the definition of a regular point means that $T - \lambda I$ is injective, and then the same relation between the kernel and the range of an operator gives us the result after some considerations of density and the closedness of $\range{T - \lambda I}$.

  \medskip

  To see that part (a) follows from part (c), it is again easiest to split up the possible cases of $\lambda$ being a complex non-real number and being a real number. If $\lambda$ is a complex non-real number, then as the spectrum of $T$ is contained in the real numbers by Proposition \eqref{lbl_sa_operator_real_spectrum}, it is in the resolvent set, as required. If it is a real number, then $\range{T - \lambda I}$ being the entirety of $\HS$ means that $T - \lambda I$ is surjective. By using the relationship between the kernel and the range of an operator given in in Proposition \eqref{lbl_prop_properties_of_adjoints}(a), we then see that $T - \lambda I$ is also injective. The result then follows from  Proposition \eqref{lbl_prop_spectrum_and_adjoint}(a). The interested reader is encouraged to see the full details in Section \eqref{proof_lbl_corollary_sa_op_and_regular_points}.
\end{proof}

Recall that in Proposition \eqref{lbl_resolvent_and_regular_point_relation}, we showed that for a general closed operator, its spectrum was always closed. We had to omit the proof, as it relied on ideas outside the scope of our work. However, it turns out that our previous result gives us the tools to show that the spectrum of a self-adjoint operator is closed. Where this is an implication of Proposition \eqref{lbl_resolvent_and_regular_point_relation}, we include it as the final result of this section for completeness.

\begin{theorem}[{\cite[Theorem 10.4-2]{kreyszig}}]\label{lbl_sa_op_closed_spectrum}
  Suppose that $T$ is a self-adjoint operator in $\HS$. Then, $\rho(T)$ is open, and consequently $\sigma(T)$ is closed.
\end{theorem}
\begin{proof}
  We take this proof directly from the proof of {\cite[Theorem 10.4-2]{kreyszig}}, and start by showing the resolvent set of $T$ is open, as that will imply that the spectrum is closed. Suppose that $\lambda$ is some point in the resolvent set of $T$. By Proposition \eqref{lbl_corollary_sa_op_and_regular_points}, this means that $\lambda$ must be a regular point of $T$. Therefore, there exists some  real constant $c_\lambda > 0$ such that
  \begin{equation*}
    c_\lambda \norm{x}
    \leq
    \norm{(T - \lambda I)x}
  \end{equation*}
  for all $x$ in the domain of $T$. Now, suppose that $\mu$ is a complex number such that \[\abs{\mu - \lambda} < \frac{c_\lambda}{s}.\] By the triangle inequality of the norm, we have that
  \begin{align*}
    \norm{(T - \lambda I)x}
    &=
    \norm{Tx - \lambda x} \\
    &=
    \norm{Tx - \mu x + \mu x -  \lambda x} \\
    &\leq
    \norm{Tx - \mu x} + \norm{(\mu - \lambda) x} \\
    &=
    \norm{(T - \mu I)x} + \abs{\mu - \lambda}\norm{x}.
  \end{align*}
  Re-arranging and using our other inequalities then gives us that
  \begin{align*}
    \norm{(T - \mu I)x}
    &\geq
    \norm{(T - \lambda I)x} - \abs{\mu - \lambda}\norm{x} \\
    &\geq
    c_\lambda \norm{x} - \frac{c_\lambda}{2}\norm{x} \\
    &=
    \frac{c_\lambda}{2}\norm{x}.
  \end{align*}
  Now, as $c_\lambda > 0$, clearly we have that $\frac{c_\lambda}{2} > 0$ too. This means that $\mu$ is a regular point for $T$ too. By Proposition \eqref{lbl_corollary_sa_op_and_regular_points}, this is equivalent to $\mu$ also being in the resolvent set of $T$. As our $\mu$ was chosen arbitrarily apart from satisfying the ienquality $\abs{\mu - \lambda} < \frac{c_\lambda}{2}$, this means that every point in the resolvent set centres an open ball of radius $\frac{c_\lambda}{2}$. Therefore, $\rho(T)$ is an open set.

  \medskip

  The fact that $\sigma (T)$ is closed is a direct consequence of $\rho(T)$ being open. A set is closed if and only if its complement is open; as $\rho(T)$ is the complement of $\sigma(T)$ and $\rho(T)$ is open, it follows that $\sigma(T)$ is closed.
\end{proof}

% {\large \textbf{delete me?}}
%
% Recall that for an operator $T$, it is called {\emph{normal}} if $T^*T = TT^*$. it is not a surprise that normal operators can be unbounded. It does, however, turn out that we have the following criteria to determine if a closed operator is normal: specifically, it is normal if we have a {\emph{Cartesian decomposition}} self-adjoint operators.
%
% \begin{proposition}[Analysis  now, prop 5.1.10]
%   Let $T$ be a closed operator in $\HS$. Then, the following are equivalent:
%   \begin{enumerate}[label = (\alph*)]
%     \item $T$ is normal.
%     \item $\dom{T} = \dom{T^*}$ and for every $x \in \dom{T} = \dom{T^*}$, we have that $\norm{T^*x} = \norm{Tx}$.
%     \item There exist self-adjoint operators $A, B$ in $\HS$ such that
%     \begin{enumerate}
%       \item $T = A + iB$,
%       \item $T^* = A - iB$,
%       \item For all $x \in \dom{T}$, we have that $\norm{Tx} = \sqrt{\norm{Ax}^2 + \norm{Bx}^2}$,
%       \item $A$ is the closure of the operator $\frac{1}{2}\big( T + T^* \big)$ in $\HS$, and
%       \item $B$ is the closure of the operator $\frac{i}{2}\big(T - T^* \big)$ in $\HS$.
%     \end{enumerate}
%     In general, if such $A$ and $B$ exist, we call $A$ the {\emph{real part of $T$}}, $\text{real}(T)$, and $B$ the {\emph{imaginary part of $T$}}, $\text{im}(T)$.
%   \end{enumerate}
% \end{proposition}
% \begin{proof}
%   Where it is not a difficult proof, we omit it due to its reliance on the topological concept of a {\emph{net}}; for the proof, please see {\cite[Proposition 5.1.10]{analysis_now}}, and for an introduction to nets, please see {\cite[Chapter 1.3]{analysis_now}}.
% \end{proof}

\subsection{Essentially self-adjoint operators}
We now move on to the final class of operators we will look at, known as the {\emph{essentially self-adjoint operators}}. These are a type of symmetric operator, and every symmetric operator is closable by Corollary \eqref{lbl_prop_symmetric_op_closable}.

\begin{definition}[{\cite[Definition 9.7]{Hall2013}}]
  An operator $T$ in $\HS$ is called {\emph{essentially self-adjoint}} if it is symmetric and its closure, $\overline{T}$, is self-adjoint.
\end{definition}

Whether or not an operator is self-adjoint or essentially self-adjoint very much depends on its domain and its underlying Hilbert space. We now see an example of the reliance of the domain and Hilbert space. We omit the proofs, as where they are not difficult, they are quite lengthy in their details. Recall that $\text{supp}(f)$ refers to the {\emph{support}} of a function $f$, as defined in Definition \eqref{lbl_def_support}.

\begin{example}[{\cite[Example 6.1]{conway}}, {\cite[Proposition 9.29]{Hall2013}},{\cite[Proposition 9.26]{Hall2013}}] \label{lbl_example_sa_esa_not_esa}
    Let $P_1$ and $P_2$ be operators in $L^2(\R)$ and let $P_3$ be an operator in $L^2[0,1]$, each defined by
    \begin{align*}
      \dom{P_1}
        &= \big\{f \in L^2(\R) \colon \text{f is absolutely continuous on all bounded intervals of $\R$,}\\&\qquad\qquad\qquad\quad \text{$f' \in L^2(\R)$}\big\}, \\
        P_1 f &= i f', \\
      \dom{P_2}
        &= \set{f \colon \R \to \C \,\,\text{is smooth} \colon \text{supp}(f) \,\text{is compact in $\R$} }, \\
        P_2 f &= i f' ,\,\text{and}\\
      \dom{P_3}
        &= \big\{f \in L^2\left([0,1]\right) \colon \text{$f$ is continuously differentiable on $[0,1]$ and}\\&\qquad\qquad\qquad\qquad\,\,\,\,\text{$f(0)=0=f(1)$}\big\}, \\
        P_3 f &= i f'.
    \end{align*}
    Then, we have that
    \begin{enumerate}[label = (\alph*)]
      \item $P_1$ is self-adjoint; for details, please see {\cite[Example 6.1]{conway}}.
      \item $P_2$ is essentially self-adjoint; for details, please see the entirety of {\cite[Chapter 9.7]{Hall2013}}.
      \item $P_3$ is not essentially self-adjoint; for details, please see the entirety of {\cite[Chapter 9.6]{Hall2013}}.
    \end{enumerate}
    For the proof of $P_2$ and $P_3$, we note that {\cite[Proposition 9,26, 9.29]{Hall2013}} express $P_2$ and $P_3$ as being multiplied by an extra constant $\hbar$ in their formula. We remove this here, as we introduce $\hbar$ when we talk about quantum physics, and as multiplication by a real constant does not change the essentially self-adjointness properties of the operator.
\end{example}

We now move on to investigating the properties of essentially self-adjoint operators. For instance, an essentially self-adjoint operator always has a unique self-adjoint extension.


\begin{proposition}[{\cite[Proposition 9.11]{Hall2013}}]\label{lbl_prop_esa_has_closure_unique_sa_extension}
  Let $T$ be an essentially self-adjoint operator in $\HS$. Then, the closure of $T$, $\overline{T}$, is the unique self-adjoint extension of $T$.
\end{proposition}
\begin{proof}
  We model this proof off of the proof of {\cite[Proposition 9.11]{Hall2013}}. Suppose that $T$ is an essentially self-adjoint operator. By definition, this means that $\overline{T}$ is a self-adjoint extension of $T$. Now suppose that $S$ is another self-adjoint extension of $T$. As $S$ is self-adjoint, it must be closed by Proposition \eqref{lbl_prop_adjoint_closed}. Now, as $\G(\overline{T})$ is the smallest closed set containing $\G(T)$, this clearly means that we have \[\overline{T} \subset S\] with possible equality. By Proposition \eqref{lbl_prop_properties_of_adjoints}(c), we therefore have that \[S^* \subset \overline{T}^{\,*}.\] Now, as both $S$ and $\overline{T}$ are self-adjoint, we have that $S \subset \overline{T} \subset S,$ which is true if and only if $\overline{T} = S$. Therefore, if $T$ is closable, we must have that $\overline{T}$ is the unique self-adjoint closed extension of $T$.
\end{proof}

Any essentially self-adjoint operator having a unique self-adjoint extension is very useful, as if we need a self-adjoint operator, we can find an essentially self-adjoint operator and then look at the closure of said operator. This is useful in the applications of unbounded operators, such as in quantum mechanics. However, for a general operator, it can take a lot of work to determine from the definition essentially self-adjointness or self-adjointness. Fortunately, there are easier ways to determine if an operator is essentially self-adjoint or self-adjoint.

\begin{theorem}[{\cite[Theorem 9.21, Corollary 9.22]{Hall2013}}]\label{lbl_thrm_esa_criteria}
  Let $T$ be a symmetric operator in $\HS$. Then, the following are equivalent:
  \begin{enumerate}[label = (\alph*)]
    \item $T$ is essentially self-adjoint.
    \item $\range{T \pm iI}$ are dense subspaces of $\HS$.
    \item $\ker{T^* \mp iI} = \set{0}$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  We start by showing the equivalence of (b) and (c), which {\cite[p.179]{Hall2013}} points out is a trivial consequence of Proposition \eqref{lbl_prop_properties_of_adjoints}. Indeed, Proposition \eqref{lbl_prop_properties_of_adjoints} gives us that
  \begin{align*}
    \left( \range{T \pm iI} \right)^\perp
    &=
    \ker{(T^* \pm iI)^*} & \text{by Proposition \eqref{lbl_prop_properties_of_adjoints}(a)}\\
    &=
    \ker{T^* \mp iI} & \text{by Proposition \eqref{lbl_prop_properties_of_adjoints}(f)},
  \end{align*}
  Now, $\range{T \pm iI}$ are dense if and only if $\left( \range{T \pm iI} \right)^\perp = \set{0}$, which gives us that $\ker{T^* \mp iI} = \set{0}$. Therefore, (b) implies (c). Now, if $\ker{T^* \mp iI} = \set{0}$, then we have that $\range{T \pm iI} = \set{0}$, which is true if and only they are dense. Therefore, (c) implies (b), meaning that (b) and (c) are equivalent.

  \medskip

  We now recreate the proof of the equivalence of (a) and (b) from the proof of {\cite[Theorem 9.21]{Hall2013}}. First, suppose that $T$ is essentially self-adjoint. By  definition, this means that $\overline{T}$ is self-adjoint, and it is also the unique self-adjoint extension of $T$ by Proposition \eqref{lbl_prop_esa_has_closure_unique_sa_extension}. By Theorem \eqref{lbl_thrm_densely_defined_and_closability}(a), we also have that $T^* = \left( \overline{T}\right)^*$. By now applying Proposition \eqref{lbl_prop_properties_of_adjoints}(a) and (f), we see that
  \begin{align*}
    \left( \range{T \pm iI} \right)^\perp
    &=
    \ker{(T \pm iI)^*} \\
    &=
    \ker{T^* \mp iI} \\
    &=
    \ker{\left(\overline{T}\right)^* \mp iI} \\
    &=
    \ker{\overline{T} \mp iI}.
  \end{align*}
  Now, as $\overline{T}$ is self-adjoint, the proof of Theorem \eqref{lbl_sa_operator_real_spectrum} shows that $\pm i$ are regular points for $\overline{T}$ and that $\overline{T} \mp \lambda I$ is injective due to it. Therefore, we have that
  \begin{equation*}
    \left( \range{T \pm iI} \right)^\perp
    =
    \set{0},
  \end{equation*}
  which is true if and only if $\range{T \pm iI}$ are dense.

  \medskip

  Now suppose that $\range{T \pm i I}$ are dense. Now, Corollary \eqref{lbl_prop_symmetric_op_closable} tells us that any symmetric operator is closable, and we also have from Theorem \eqref{lbl_thrm_densely_defined_and_closability}(a) that $T^* = \left( \overline{T}\right)^*$ . Now, Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension} tells us that the adjoint of a symmetric operator is also an extension, and Proposition \eqref{lbl_prop_adjoint_closed} tells us that this adjoint is closed. Therefore, we have that $\left( \overline{T} \right)^*$ is a closed extension of $T$, which therefore means that it must be a closed extension of $\overline{T}$. As $\left( \overline{T} \right)^* = T^*$, this implies that $\overline{T}$ is indeed symmetric. By following the proof of  Theorem \eqref{lbl_sa_operator_real_spectrum}, we get that for all $x$ in $\dom{\overline{T}}$,
  \begin{align*}
    \norm{(\overline{T} \pm i I)x}^2
    &\geq
    (\mp 1)^2\norm{x}^2
    =
    \norm{x}^2
  \end{align*}
  which by the same reasoning in the proof of Theorem \eqref{lbl_sa_operator_real_spectrum} means that the operators $\overline{T} \pm iI$ are injective. Importantly, we also have that as $\mp i$ are regular points of $\overline{T}$, we have that $\range{T \mp i I}$ is closed by Proposition \eqref{lbl_prop_properties_of_regular_points}(d). Now, as $\overline{T}$ is an extension of $T$, we have that $\overline{T} \pm i I$ is an extension of $T \pm i I$, which means that $\range{\overline{T} \pm i I}$ contains $\range{T \pm \lambda I}$. As  $\range{T \mp i I}$ is dense, this also means that   $\range{\overline{T} \pm i I}$ is dense. As $\range{\overline{T} \pm i I}$ is closed and dense, we must have that $\range{\overline{T} \pm i I} = \HS$, as the closure of a dense set is the entire space.

  \medskip

  Now, by Proposition \eqref{lbl_prop_properties_of_adjoints}(f), we have that $\left( \overline{T} \mp iI \right)^* = \left( \overline{T} \right)^* \pm iI$. As $\overline{T}$ is symmetric, Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension} tells us that $\left( \overline{T} \right)^*$ is an extension of $\overline{T}$, which in turn means that $\left( \overline{T} \right)^* \pm iI = \left( \overline{T} \mp iI \right)^*$ is an extension of $\overline{T} \pm iI$.

  In the hopes of a contradiction, we now suppose that $\dom{\left( \overline{T}\right)^* \pm iI}$ is strictly bigger than $\dom{\overline{T} \pm iI}$. Now, as $T$ is essentially self-adjoint, $\overline{T}$ is self-adjoint, so it is symmetric. By Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension}, this means that $\left(\overline{T} \right)^*$ is an extension of $\overline{T}$. As $\overline{T}$ is an extension of $T$, we therefore have that
  \begin{equation*}
    \dom{T} \subset \dom{\overline{T}} \subset \dom{\left(\overline{T}\right)^*}.
  \end{equation*}

  Now, as $\range{T \pm iI} = \HS$, we must have that $\left( \overline{T} \right)^* \pm iI$ is not injective, as by assumption we have that $\dom{\left(\overline{T}\right)^*}$ is bigger than $\dom{T}$. This means that
  \begin{align*}
    \ker{\left( \overline{T} \right)^* \pm iI}
    &=
    \ker{\left( \overline{T} \pm iI \right)} \\
    &=
    \ker{\left({T} \mp iI \right)^*} \\
    &\neq \set{0}.
  \end{align*}
  However, Proposition \eqref{lbl_prop_properties_of_adjoints}(a) tells us that
  \begin{equation*}
    \left( \range{T \mp iI} \right)^\perp
    =
    \ker{\left( T \mp iI \right)^*},
  \end{equation*}
  which is not equal to $\set{0}$ if and only if $\range{T \mp iI}$ is not dense. This goes against our assumptions; therefore, $\dom{\left( \overline{T}\right)^* \pm iI} = \dom{\overline{T} \pm iI}$, meaning that $ \left( \overline{T}\right)^* \pm iI = \overline{T} \pm iI $. This is true if and only if $\left( \overline{T}\right)^* = \overline{T}$, meaning that $\overline{T}$ is self-adjoint. As it is an extension of $T$, we therefore get that $T$ is essentially self-adjoint.
\end{proof}

This result is a powerful tool for us. For instance, the following corollary tells us that if we have a symmetric operator, knowledge of its eigenvectors can tell us if it is essentially self-adjoint.

\begin{corollary}[{\cite[Example 9.25]{Hall2013}}]\label{lbl_corollary_sym_with_eigenvectors_onb_is_esa}
  Let $T$ be a symmetric operator in $\HS$ which has eigenvectors. If the set of eigenvectors for $T$ makes an orthonormal basis for $\HS$, then $T$ is essentially self-adjoint.
\end{corollary}
\begin{proof}
  We take this proof directly from the proof of {\cite[Example 9.25]{Hall2013}}. Suppose that $v_j$ is an eigenvector for $T$ with corresponding eigenvalue $\lambda_j$. By Proposition \eqref{lbl_prop_sym_ops_real_eigenvalues}, all eigenvalues of $T$ are real due to it being symmetric, so $\lambda_j \in \R$. Now, we see that
  \begin{equation*}
    (T \pm iI)v_j = Tv_j \pm i v_j = \lambda v_j \pm i v_j = (\lambda \pm i)v_j.
  \end{equation*}
  As $\lambda_j$ is real, $\lambda_j \pm i$ is non-negative. Therefore, $\range{T \pm iI}$ contains non-zero multiples of every eigenvector for $T$. Now, remembering that the span of a set refers to the {\emph{finite}} linear combinations of its elements, as $\range{T \pm i I}$ is a subspace, it follows that
  \begin{equation*}
    \text{span}\set{v_j}_{j \in \N}
    \subset
    \range{T \pm iI}.
  \end{equation*}
  By Definition \eqref{lbl_def_onb}, the eigenvectors forming an orthonormal basis of $\HS$ is equivalent to $\text{span}\set{v_j}_{j \in \N}$ being dense in $\HS$. Therefore, as $\text{span}\set{v_j}_{j \in \N}$ is a subset of $\range{T  \pm i I}$, $\range{T \pm i I}$ is dense. By Theorem \eqref{lbl_thrm_esa_criteria}, this is equivalent to $T$ being essentially self-adjoint.
\end{proof}

With this ability to tell when an operator is essentially self-adjoint, we can now develop another way to determine if an operator is self-adjoint.

\begin{theorem}[{\cite[Proposition 9.23]{Hall2013}}]\label{lbl_thrm_sa_criteria}
  Let $T$ be a symmetric operator in $\HS$. Then, the following are equivalent:
  \begin{enumerate}[label = (\alph*)]
    \item $T$ is self-adjoint.
    \item The operators $T \pm iI$ are surjective; that is, $\range{T \pm iI} = \HS$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  We take this proof from the proof of {\cite[Proposition 9.23]{Hall2013}}. First, suppose that $T$ is a self-adjoint operator in $\HS$. By Theorem \eqref{lbl_thrm_densely_defined_and_closability}(a), we have that
  \begin{equation*}
    \left( \overline{T} \right) = T^*,
  \end{equation*}
  which is equal to $T$ by our self-adjointness assumption. By Theorem \eqref{lbl_thrm_densely_defined_and_closability}(a)(ii) and our self-adjointness of $T$, we also have that
  \begin{equation*}
    \overline{T}
    =
    \left( T^* \right)^*
    =
    T^*
    =
    T.
  \end{equation*}
  This means that $\overline{T}$ is also self-adjoint and that $T$ is in fact a closed operator. Importantly, we technically have that $T$ is essentially self-adjoint, which means that $\range{T \pm i I}$ are dense by Theorem \eqref{lbl_thrm_esa_criteria}. By the proof of Theorem \eqref{lbl_thrm_esa_criteria}, we have that $\mp i$ are regular points of $T$, which by Proposition \eqref{lbl_prop_properties_of_regular_points}(d) means that $\range{T \pm i I}$ is closed. As $\range{T \pm i I}$ is closed and dense, we must have that $\range{T \pm i I} = \HS$ as the closure of a dense set is the entire space.

  \medskip

  Now suppose that $\range{T \pm i I} = \HS$. As $\HS$ is trivially dense in itself, we have that $T$ is essentially self-adjoint by Theorem \eqref{lbl_thrm_esa_criteria}. This means that $\overline{T}$ is self-adjoint. By Theorem \eqref{lbl_thrm_densely_defined_and_closability}(a) and the self-adjointness of $\overline{T}$, we have that
  \begin{equation*}
    \overline{T}
    =
    \left( \overline{T} \right)^*
    =
    T^*,
  \end{equation*}
  which means that $T^*$ is also self-adjoint. We now make a similar argument to show that $T = T^*$ as we did in Theorem \eqref{lbl_thrm_esa_criteria}. As $T^* = \overline{T}$ is an extension of $T$ by Proposition \eqref{lbl_prop_sym_iff_adjoint_is_extension}, suppose that $\dom{T}$ is contained in $\dom{T^*}$.  By the proof of Theorem \eqref{lbl_thrm_esa_criteria}, we have that $\mp i$ are regular points of $T^*$, and the fact that
  \begin{equation*}
    (\mp i)^2 \norm{x}^2 = \norm{x}^2 \leq \norm{T^* \pm i I}^2
  \end{equation*}
  means that
  \begin{equation*}
    \norm{x} \leq \norm{T^* \pm i I},
  \end{equation*}
  which makes $T^* \pm i I$ injective by the same argument given in the proof of Theorem \eqref{lbl_sa_operator_real_spectrum}. However, if $\dom{T^*}$ is strictly larger than $\dom{T}$, we could not have that $T^* \pm i I$ is injective. This is the same reasoning as in the proof of Theorem \eqref{lbl_thrm_esa_criteria}; if $\dom{T^*}$ is strictly larger than $\dom{T}$, $\range{T \pm iI} = \HS$ means that $T^* \pm iI$ would have multiple elements mapped to the same element. This means that $\dom{T^*} = \dom{T}$, and as $T^*$ is an extension of $T$, we have that $T = T^*$. As $T^*$ is self-adjoint, this means that $T$ self-adjoint too.
\end{proof}

Our final result of this section is the {\emph{Kato-Rellich theorem}}. This gives us a specific case of when the addition of two unbounded operators is unbounded. It is a very important theorem in quantum mechanics, where we often would like to add self-adjoint operators together and get another self-adjoint operator. For an example of this application, please see {\cite[Chapter 8.3]{konrad}} or Theorem \eqref{lbl_thrm_hamiltonian_with_potential_SA} in our next chapter. Where we take this result from {\cite[Theorem 9.37]{Hall2013}}, it can also be found in {\cite[Theorem 8.5]{konrad}} and {\cite[Theorem 6.4]{teschl}}. We omit the proof, as in all three sources it requires a lot of build-up.

\begin{theorem}[The Kato-Rellich theorem, {\cite[Theorem 9.37]{Hall2013}}]\label{lbl_thrm_kato_rellich}
  Let $T$ and $S$ be two operators in $\HS$ such that $\dom{T} \subset \dom{S}$ and such that there exist real constants $0 < a < 1$ and $b > 0$ with
  \begin{equation*}
    \norm{Sx} \leq a \norm{Tx} + b \norm{x}
  \end{equation*}
  for all $x \in \dom{T}$. Then, $T + S: \dom{T} \to \HS$ is a self-adjoint operator too. Furthermore, $T + S$ is essentially self-adjoint on any subspace of $\dom{T}$ which makes $T$ essentially self-adjoint when restricted to it. Finally, if for all $x \in \dom{T}$ we have that $\ip{Tx, x} \geq 0$, then $\sigma(T+S)$ is bounded below by $-\frac{b}{1-a}$.
\end{theorem}

\begin{remark}
  As {\cite[Definition 3.2]{konrad}}, {\cite[p.68]{teschl}}, and {\cite[Definition 9.19]{Hall2013}} tells us, if $T$ is an operator in $\HS$ such that for all $x \in \dom{T}$ we have that
    \begin{equation*}
      \ip{Tx, x} \geq 0,
    \end{equation*}
    we call $T$ a {\emph{positive operator}}. This is the same as in the case of an operator defined over the entirety of $\HS$, just we have to take into account our domain. Positive operators are sometimes called {\emph{non-negative operators}}.
\end{remark}
%
% \subsection{Spectral properties}
%
% In this section, our goal is to create a spectral theorem for self-adjoint operators. Specifically, we wish to find a result which classifies self-adjoint operators in terms of simpler operators. We will see that this classification is in the form of an integral equation. This then allows us a framework to work out functions of operators in a relatively simple way; a so-called {\emph{functional calculus}}. Before we look at the spectral theorem, we will need to generalise some of our measure theory.
%
% \subsubsection{Spectral measures}
%
% Recall that for a measurable space $(\Omega, \mathcal{F})$, a measure is a mapping $\mu: \mathcal{F} \to [0,\infty]$ such that the empty set gets mapped to 0 and we have countable additivity. We can generalise this definition of a measure to have domains other than the extended real line. Recall that the notation $\mathrm{B}(\HS)$ refers to the set of all bounded operators defined on the entirety of a Hilbert space $\HS$.
%
% \begin{definition}[{\cite[Definition 7.10]{Hall2013}}]
%   Let $(\Omega, \mathcal{F})$ be a measurable space and let $\HS$ be any Hilbert space. A {\emph{spectral measure}}, also known more accurately as a {\emph{projection-valued measure}}, is a mapping $\mu: \mathcal{F} \to \mathrm{B}(\HS)$ such that
%   \begin{enumerate}[label = (\alph*)]
%     \item For every set $E$ in $\mathcal{F}$, $\mu(E)$ is an orthogonal projection.
%     \item $\emptyset$ gets mapped to the zero operator, $\mu(\emptyset) = 0$, and $\Omega$ gets mapped to the identity operator, $\mu(\Omega) = I$.
%     \item If $(E_n)$ is a family of disjoint sets in $\mathcal{F}$, then for any $x \in \HS$ we have that
%     \begin{equation*}
%       \mu\left( \bigcup_{j=1}^{\infty} E_j \right)x = \sum_{j=1}^{\infty}\mu(E_j)x.
%     \end{equation*}
%     \item For any sets $E_1$ and $E_2$ in $\mathcal{F}$, we have that
%     \begin{equation*}
%       \mu(E_1 \cap E_2) = \mu(E_1)\mu(E_2).
%     \end{equation*}
%   \end{enumerate}
% \end{definition}
% \begin{remark}
%   Property (b) and (c) clearly mimic the definition of our standard measure theoretic measure.
% \end{remark}
%
% Recall that for two self-adjoint bounded operators $S$ and $T$ defined on the entirety of $\HS$, we can define a partial order $\leq$ by saying that $S \leq T$ if
% \begin{equation*}
%   \ip{Sx, x} \leq \ip{Tx, x}
% \end{equation*}
% for all $x$ in $\HS$. This partial order allows us to see that a spectral measure satisfies other properties we want a measure to obey.
%
% \begin{proposition}[\textbf{moretti, prop 8.44}]
%   Let $\Omega, \mathcal{F}$ be a measure space and let $\mu: \mathcal{F} \to \mathrm{B}(\HS)$ be a spectral measure. Then, $\mu$ is monotone and subadditive; that is,
%   \begin{enumerate}[label = (\alph*)]
%     \item If $E, F \in \mathcal{F}$ such that $E \subset F$, we have that $\mu(E) \leq \mu(F)$.
%     \item If $E_j$ is a family in $\mathcal{F}$, then for all $x \in \HS$ we have that
%     \begin{equation*}
%       \ip{\mu\left( \bigcup_{j=1}^{\infty} E_j \right) x, x}
%       =
%       \sum_{j = 1}^{\infty} \ip{\mu(E_j) x, x}.
%     \end{equation*}
%   \end{enumerate}
% \end{proposition}
% \begin{proof}
%   \textbf{moretti, prop 8.44}
% \end{proof}
%
% The important of spectral measures is that we can define an integral with respect to the spectral measure. We first note that for a spectral measure $\mu$, by fixing a vector $x \in \HS$ we can induce a real-valued measure $\mu_x$.
%
% \begin{proposition}[{\cite[p.138]{Hall2013}}]
%   Let $\Omega, \mathcal{F}$ be a measure space and let $\mu: \mathcal{F} \to \mathrm{B}(\HS)$ be a spectral measure. Then, for a vector $x \in \HS$, the function $\mu_x: \mathcal{F} \to [0, \infty]$ defined by
%   \begin{equation*}
%     \mu_x(E) = \ip{\mu(E) x, x}
%   \end{equation*}
%   for all $E \in \mathcal{F}$ defines a measure.
% \end{proposition}
% \begin{proof}
%   {\large \textbf{figure me out}}
% \end{proof}
%
% \begin{theorem}[{\cite[Proposition 7.11]{Hall2013}}, \textbf{moretti, remark 8.48, def 8.49}]
%   Let $\Omega, \mathcal{F}$ be a measure space and let $\mu: \mathcal{F} \to \mathrm{B}(\HS)$ be a spectral measure. There then exists a unique linear map from the set of bounded, measurable functions on $\mathcal{F}$ to $\mathrm{B}(\HS)$ given by
%   \begin{equation*}
%     \int_\Omega f\,d\mu = A_f,
%   \end{equation*}
%   where $A_f$ is the bounded linear operator given by
%   \begin{equation*}
%     \int_\Omega f\,d\mu_x = \ip{A_f x, x}
%   \end{equation*}
%   for all $x \in \HS$.
% \end{theorem}
% \begin{proof}
%   {\cite[Proposition 7.11]{Hall2013}}
%
%   {\large \textbf{figure me out and add properties of the integral in that theorem}}
% \end{proof}
